# ğŸ—£ï¸ Offline,  Hindi Voice Assistant on Raspberry Pi
## BHARATH AI-SoC  Student Challenge

---
## ğŸ“‘ Table of Contents

- [Problem Statement](#-problem-statement)
- [Objective](#-objective)
- [System Architecture](#-system-architecture)
  - [High-Level Pipeline](#-1ï¸âƒ£-high-level-embedded-speech-pipeline)
  - [Privacy & Data Flow](#-2ï¸âƒ£-data-flow-diagram)
  - [ARM CPU Optimization](#-3ï¸âƒ£-arm-cpu-optimization-flow)
  - [Software Architecture](#-4ï¸âƒ£-software-architecture-diagram)
- [Hardware Used](#-hardware-used)
- [Software Stack](#-software-stack)
- [Core Implementation Details](#-core-implementation-details)
  - [Speech-to-Text (ASR)](#-ğŸ”·-1ï¸âƒ£-speech-to-text-(asr))
  - [Intent Recognition](#-ğŸ”·-2ï¸âƒ£-intent-recognition)
  - [Text-to-Speech (TTS)](#-ğŸ”·-3ï¸âƒ£-text-to-speech-(tts))
- [ARM CPU Optimization Techniques](#-arm-cpu-optimization-techniques)
- [Performance Results](#-performance-results)
- [Privacy-Preserving Design](#-privacy-preserving-design)
- [Repository Structure](#-repository-structure)
- [Setup & Execution](#-setup--execution)
- [Deliverables](#-deliverables-included)
- [Learning Outcomes](#-learning-outcomes)
- [Conclusion](#-conclusion)



## ğŸ“Œ Problem Statement

Develop a low-latency, privacy-preserving voice assistant on an Arm-based SBC (Raspberry Pi 4) that processes Hindi voice commands entirely offline.

The assistant must:

* Operate fully on CPU
* Avoid cloud dependency
* Support local Hindi queries (time, date, greetings, etc.)
* Maintain low response latency

---

## ğŸ¯ Objective

To design and implement an embedded speech pipeline on Raspberry Pi that:

* Captures Hindi voice input
* Converts speech to text using offline ASR
* Identifies user intent using Python logic
* Generates spoken responses using offline TTS
* Runs completely on ARM CPU without accelerators

---

# ğŸ§± System Architecture

## ğŸ”· 1ï¸âƒ£ High-Level Embedded Speech Pipeline

```
+----------------------+
|      User (Hindi)    |
+----------+-----------+
           |
           v
+----------------------+
|    USB Microphone    |
+----------+-----------+
           |
           v
+----------------------+
|  Audio Capture       |
|  (PyAudio - 16kHz)   |
+----------+-----------+
           |
           v
+-------------------------------+
|  Offline ASR Engine           |
|  (Wav2Vec2 - Quantized INT8)  |
+----------+--------------------+
           |
           v
+-------------------------------+
|  Intent Recognition Engine    |
|  (Rule-Based Python Logic)    |
+----------+--------------------+
           |
           v
+-------------------------------+
|  Command Processing Layer     |
+----------+--------------------+
           |
           v
+-------------------------------+
|  Offline TTS Engine           |
|  (eSpeak-NG Hindi)            |
+----------+--------------------+
           |
           v
+----------------------+
|      Speaker Output  |
+----------------------+
```

âœ” Entire pipeline runs on Raspberry Pi CPU
âœ” No internet
âœ” No cloud

---

## ğŸ”· 2ï¸âƒ£ Data Flow Diagram

```
        Voice Input
             |
             v
    +-------------------+
    |   Local ASR       |
    |  (On Device)      |
    +-------------------+
             |
             v
    +-------------------+
    | Intent Detection  |
    +-------------------+
             |
             v
    +-------------------+
    |  Local TTS        |
    +-------------------+
             |
             v
        Audio Output
```

ğŸš« No external servers
ğŸš« No API calls
ğŸš« No cloud processing

---

## ğŸ”· 3ï¸âƒ£ ARM CPU Optimization Flow

```
Model Loading
      |
      v
Dynamic Quantization (INT8)
      |
      v
CPU Inference Only
      |
      v
Low-Latency Response
```

âœ” Optimized for ARM Cortex-A72
âœ” No accelerators
âœ” CPU-only execution

---

## ğŸ”· 4ï¸âƒ£ Software Architecture Diagram

```
Assistant.py
     |
     +-- record_audio()
     |
     +-- ASR Inference (Wav2Vec2)
     |
     +-- process_command()
             |
             +-- intent_engine.detect_intent()
     |
     +-- speak()  --> eSpeak-NG
```

---


### ğŸ”· End-to-End Embedded Pipeline

```
User (Hindi Speech)
        â†“
USB Microphone
        â†“
Audio Capture (PyAudio, 16kHz)
        â†“
Wav2Vec2 ASR Model (Offline, Quantized)
        â†“
Intent Recognition Engine (Python)
        â†“
Command Processing
        â†“
eSpeak-NG (Offline TTS)
        â†“
Speaker Output
```

âœ” Entire pipeline runs locally on Raspberry Pi CPU
âœ” No internet access required

---

## ğŸ›  Hardware Used

* Raspberry Pi 4 (ARM Cortex-A72)
* USB Microphone
* Speaker (3.5 mm Jack)
* 32GB SD Card

The system is designed to run entirely on CPU without external accelerators.

---

## ğŸ’» Software Stack

* Python 3
* PyAudio (Audio I/O)
* HuggingFace Transformers
* Fine-tuned Wav2Vec2 (Hindi ASR)
* eSpeak-NG (Hindi TTS)
* Custom Intent Recognition Engine

---

## ğŸ§  Core Implementation Details

### 1ï¸âƒ£ Speech-to-Text (ASR)

* Hindi Wav2Vec2 model
* Loaded locally using `local_files_only=True`
* Dynamic INT8 Quantization applied
* Optimized for ARM CPU inference

```python
model = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)
```

---

### 2ï¸âƒ£ Intent Recognition

Lightweight keyword-based rule engine:

```
TIME â†’ ["à¤¸à¤®à¤¯", "à¤Ÿà¤¾à¤‡à¤®"]
DATE â†’ ["à¤¤à¤¾à¤°à¥€à¤–", "à¤¦à¤¿à¤¨à¤¾à¤‚à¤•"]
GREETING â†’ ["à¤¨à¤®à¤¸à¥à¤¤à¥‡", "à¤¹à¥‡à¤²à¥‹"]
...
```

* No heavy NLP models
* Fast CPU execution
* Low memory overhead

---

### 3ï¸âƒ£ Text-to-Speech (TTS)

* eSpeak-NG (Hindi phoneme support)
* Fully offline
* Subprocess-based execution

---

## âš¡ ARM CPU Optimization Techniques

To ensure efficient execution on ARM CPU:

* âœ… Dynamic Quantization (INT8)
* âœ… Silence detection before inference
* âœ… Controlled audio frame buffering
* âœ… Lightweight intent recognition
* âœ… CPU-only execution (no accelerators)

This aligns with ARM Challenge emphasis on CPU optimization.

---

## ğŸ“Š Performance Results

Tested with 15 standard Hindi commands:

| Metric            | Result     |
| ----------------- | ---------- |
| Average Latency   | ~3 seconds |
| Word Error Rate   | ~15%       |
| CPU Peak Usage    | ~85%       |
| RAM Usage         | ~1.2 GB    |
| Offline Operation | 100%       |

The system meets the requirement of robust offline execution and supports more than 10 Hindi commands.

---

## ğŸ” Privacy-Preserving Design

The assistant ensures data sovereignty by:

* No internet usage
* No API keys
* No cloud processing
* No data logging
* All inference done locally

```
Voice â†’ Local ASR â†’ Local Intent Logic â†’ Local TTS
```

---

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ Assistant.py
â”œâ”€â”€ intent_engine.py
â”œâ”€â”€ ASR_model/
â”œâ”€â”€ Documentation.docx
â”œâ”€â”€ Report_on_ARM_Challenge.pdf
â””â”€â”€ README.md
```

---

## â–¶ï¸ Setup & Execution

### Clone Repository

```
git clone <repo-link>
cd <repo-name>
```

### Install Dependencies

```
pip install torch transformers pyaudio numpy
sudo apt install espeak-ng
```

### Run Assistant

```
python Assistant.py
```

---

## ğŸ¥ Deliverables Included

* âœ… Complete source code
* âœ… Documentation
* âœ… Optimization details
* âœ… Performance metrics
* âœ… ARM-based implementation
* âœ… Offline operation proof

---

## ğŸ“˜ Learning Outcomes

* Embedded Speech AI implementation
* ARM CPU optimization for ML inference
* Hindi ASR challenges
* Integrating ASR + NLP + TTS on constrained hardware
* Edge AI deployment without cloud

---

## ğŸ Conclusion

This project successfully demonstrates a fully offline, privacy-preserving Hindi voice assistant running entirely on ARM-based Raspberry Pi CPU. Through model quantization and lightweight intent recognition, the system achieves efficient on-device inference without cloud dependency, fulfilling the requirements of ARM Challenge Problem Statement 1.

---
